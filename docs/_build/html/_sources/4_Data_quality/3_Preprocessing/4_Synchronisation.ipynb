{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Synchronisation\n",
    "- When merging time-dependent data from different sources, matching them well is important, but also comes with some choices.\n",
    "- If time series are to be used in Machine Learning, exact synchronisation is usually needed, i.e., equal timestamps on each variable.\n",
    "- For plotting purposes different time resolution, e.g., weeks vs months, may not be a problem as long as the different cycles match up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a time series with a frequency of 1 hour and a length 72*24 hours\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(1979)\n",
    "stock = rng.standard_normal(72).cumsum() + 2\n",
    "days = pd.date_range('2021-01-01', periods=72, freq='D')\n",
    "\n",
    "rng2 = np.random.default_rng(1000)\n",
    "electricity = rng2.standard_normal(72*24).cumsum()+30\n",
    "hours = pd.date_range('2021-01-01', periods=72*24, freq='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the two series in the same plot\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(7, 2))\n",
    "ax.plot(days, stock, label='stock')\n",
    "ax.plot(hours, electricity, label='electricity')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Accumulation\n",
    "- If a higher resolution time series is to be synchronized with a lower resolution series, some type of accumulation needs to be done.\n",
    "- Things to keep in mind:\n",
    "    - Which type of accumulation should be done, e.g., sum for count data, mean for intensity data?\n",
    "    - Should we use simple statistics, robust statistics or smoothed series data?\n",
    "    - Are the low resolution recordings a series of snapshots (a) or an accumulation between (before (b)/after (d)) or around (c) timepoints (see illustration)?  \n",
    "      - This coresponds to the different uses of filters in the [Noise reduction section](../1_Signal/2_Noise_reduction.ipynb).\n",
    "      - ... which also means that it is possible to echange simple averages with other smoothers.\n",
    "\n",
    "<img src=\"https://github.com/khliland/IND320/blob/main/D2Dbook/images/Accumulation.png?raw=TRUE\" width=\"700px\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Turn the hourly series into a daily series by taking the mean of each day\n",
    "daily2 = electricity.reshape(72, 24).mean(axis=1)\n",
    "print(daily2.shape)\n",
    "daily2[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Question:__ Is the mean calculation above an accumulation of type a, b, c or d (as compared to the illustration)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Make a dataframe of days and daily\n",
    "df_days = pd.DataFrame({'days': days, 'stock': stock})\n",
    "# .. and hours and hourly\n",
    "df_hours = pd.DataFrame({'hours': hours, 'electricity': electricity})\n",
    "df_hours.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Group the hourly series by day and take the mean of each day\n",
    "daily3 = df_hours.electricity.groupby(df_hours.hours.dt.date).mean()\n",
    "daily3.name = 'electricity' # <- Will be column name in dataframe\n",
    "\n",
    "# Change name of index to days\n",
    "daily3.index.name = 'days'\n",
    "\n",
    "# Convert index to datetime\n",
    "daily3.index = pd.to_datetime(daily3.index) # <- Important for matching with other datetimes!\n",
    "daily3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate the daily series and the daily3 series\n",
    "daily4 = pd.concat([pd.DataFrame({\"stock\":stock}, index=days), daily3], axis=1)\n",
    "daily4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the two time series in daily4 using Pandas plot\n",
    "daily4.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interpolation\n",
    "- Timepoints may not match as easily as with days and hours above.\n",
    "- If one series is shifted slightly, the series are irregular in timesteps or have non-intuitive intervals, interpolation is an alternative.\n",
    "- When interpolating an irregular sequence in Pandas, one may need to resample to a higher frequency, fill the missing values and resample to the final frequency (see example below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Create a time series with irregular frequency\n",
    "irr_dates = pd.date_range('2000-01-01 00:00', periods=365, freq='D') # <- Higher accuracy applied here to enable sampling\n",
    "\n",
    "# Sample 50 random dates from irr_dates\n",
    "m = np.arange(0,365,1)\n",
    "rng.shuffle(m)\n",
    "irr_dates = irr_dates[np.sort(m[:50])].sort_values()\n",
    "\n",
    "# Create a series with random values and the sampled dates as index\n",
    "irr_series = pd.DataFrame({'values': rng.standard_normal(50)}, index=irr_dates)\n",
    "#irr_series.head()\n",
    "print(irr_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Interpolate the series to weekly frequency without intermediate resampling\n",
    "weekly = irr_series.resample('W').interpolate(\"linear\")\n",
    "weekly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the two series\n",
    "fig, ax = plt.subplots(figsize=(7, 2))\n",
    "ax.plot(irr_series, label='irregular')\n",
    "ax.plot(weekly, 'o', label='weekly')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Interpolate the series to weekly frequency after resampling to daily frequency\n",
    "daily_x = irr_series.resample('D').interpolate(\"linear\")\n",
    "weekly = irr_series.resample('D').interpolate(\"linear\").resample('W').interpolate(\"linear\")\n",
    "weekly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the two series\n",
    "fig, ax = plt.subplots(figsize=(7, 2))\n",
    "ax.plot(daily_x, 'o', label='interpolated daily')\n",
    "ax.plot(irr_series, 'o', label='irregular')\n",
    "ax.plot(weekly, label='weekly')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Time delays\n",
    "- Industrial processes often have a continuous or batchwise handling of raw materials into other materials or products.\n",
    "  - When sensors record data along the production line, matching a piece of raw material to sensor readings can be done by adding a delay to the timestamp of the measurements early in the process or subtracting time from the later measurements.\n",
    "- For some processes, the delay is a known, fixed quantity. \n",
    "  - For others the delay may be dependent on dynamic factors like raw material properties or process settings that add uncertainty to the time delay.\n",
    "  - Synchronising such data, may require optimising correlations between sensors or using more advanced warping techniques.\n",
    "  \n",
    "<img src=\"https://github.com/khliland/IND320/blob/main/D2Dbook/images/Industrial_process.png?raw=TRUE\" width=\"700px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "```{seealso} \n",
    ":class: tip\n",
    "\n",
    "## Resources\n",
    "- [Pandas groupby](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html)\n",
    "- [Pandas interpolation](https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.interpolate.html)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
