{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Streaming models\n",
    "## Static models\n",
    "- A pretrained model can be applied to a stream of data.\n",
    "- We will train a model using _scikit-learn_ and predict in a loop.\n",
    "- Then try to convert it to a _river_ streaming model before applying it to a stream of data.\n",
    "- Finally, create a streaming model directly in _river_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Load the data\n",
    "dataset = datasets.load_breast_cancer()\n",
    "X, y = dataset.data, dataset.target\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Define the steps of the model\n",
    "model = Pipeline([\n",
    "    ('scale', preprocessing.StandardScaler()),\n",
    "    ('log_reg', SGDClassifier(loss=\"log_loss\", penalty=\"l2\")) \n",
    "    # (Logistic Regression using Stochastic Gradient Descent to enable .partial_fit())\n",
    "])\n",
    "\n",
    "# Ten-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Compute the accuracy\n",
    "scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv)\n",
    "\n",
    "# Display the average score and it's standard deviation\n",
    "print(f'Accuracy: {scores.mean():.3f} (Â± {scores.std():.3f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit the model with all training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop over the test data (i.e., stream) and compute the accuracy\n",
    "acc = 0\n",
    "for x, y in zip(X_test, y_test):\n",
    "    acc += model.score(x.reshape(1, -1), y.reshape(1, -1))\n",
    "print(f'Accuracy: {acc / len(X_test) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Converting to _river_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract the mean and standard deviation of each feature\n",
    "mean = model.named_steps['scale'].mean_\n",
    "std = model.named_steps['scale'].scale_\n",
    "\n",
    "# Create a river StandardScaler and insert the mean and variance\n",
    "from river.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "ss.vars = dict(zip(dataset.feature_names, std ** 2))\n",
    "ss.means = dict(zip(dataset.feature_names, mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Wrap the Logistic Regression model\n",
    "import numpy as np\n",
    "from river.compat import convert_sklearn_to_river\n",
    "streaming_model = convert_sklearn_to_river(model.named_steps['log_reg'], classes=np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict the test set one sample at a time\n",
    "from river import metrics\n",
    "from river import stream\n",
    "metric = metrics.Accuracy()\n",
    "for x, y in stream.iter_array(X_test, y_test, feature_names=dataset.feature_names):\n",
    "    x_scaled = ss.transform_one(x)\n",
    "    y_pred = streaming_model.predict_one(x_scaled)\n",
    "    metric.update(y_pred, y)\n",
    "    # metric = metric.update(y_pred, y) # For river < 0.21\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Direct usage of _river_\n",
    "- The defaults in scikit-learn's SGDClassifier and river's LogisticRegression are different.\n",
    "- Pipelines can be made with a parenthesis and a pipe symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a pipeline using the StandardScaler and the Logistic Regression model from river\n",
    "from river import linear_model\n",
    "\n",
    "streaming_model = (StandardScaler() | linear_model.LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the streaming_model with the training data\n",
    "#dataset_train = dataset\n",
    "#dataset_train.data = X_train.copy()\n",
    "#dataset_train.target = y_train.copy()\n",
    "\n",
    "# Online learning\n",
    "for x, y in stream.iter_array(X_train, y_train, feature_names=dataset.feature_names):\n",
    "    streaming_model.learn_one(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict the test set one sample at a time\n",
    "metric = metrics.Accuracy()\n",
    "static_pred = []\n",
    "for x, y in stream.iter_array(X_test, y_test, feature_names=dataset.feature_names):\n",
    "    y_pred = streaming_model.predict_one(x)\n",
    "    static_pred.append(y_pred)\n",
    "    metric.update(y_pred, y)\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "```{note}\n",
    "The training regimes are different, so we cannot expect river and scikit-learn to give exactly the same models.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Dynamic models\n",
    "- For comparison, we can continue learning during prediction of the test set (given that labels come together with the streaming data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Learn and predict the test set one sample at a time\n",
    "metric = metrics.Accuracy()\n",
    "dynamic_pred = []\n",
    "for x, y in stream.iter_array(X_test, y_test, feature_names=dataset.feature_names):\n",
    "    y_pred = streaming_model.predict_one(x)\n",
    "    streaming_model.learn_one(x, y)\n",
    "    dynamic_pred.append(y_pred)\n",
    "    metric.update(y_pred, y)\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "__Inspect predictions one by one__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot y_test together with static and dynamic predictions in two plots above each other\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(y_test, label='y_test')\n",
    "plt.plot(static_pred, label='static_pred')\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(y_test, label='y_test')\n",
    "plt.plot(dynamic_pred, label='dynamic_pred')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "__Comment:__ In this case, one classification changed to the worse with the dynamic model, the rest stayed the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## River vs scikit-learn\n",
    "- First of all, these are only examples of machine learning frameworks.\n",
    "    - There are several other established and polished packages to use in their places, e.g., Quix, (scikit-multiflow + creme = River), PyTorch, TensorFlow, theano, PyCaret, OpenCV, etc.\n",
    "- River is built from the ground up with streaming data in mind.\n",
    "    - Pre-processors, regressors and classifiers are all incremental.\n",
    "    - A host of convenience functions for online/batch-wise learning are available.\n",
    "- scikit-learn is built for tabular data.\n",
    "    - _.partial\\_fit()_ is available for some pre-processors, regressors and classifiers.\n",
    "    - Stream handling can be manually coded or helped by River and friends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Live reading of Twitch chat, revisited\n",
    "- Requires a free account on [Twitch](https://twitch.tv) and obtaining an [oauth autentication token](https://twitchapps.com/tmi/).\n",
    "- We will use River's [TwitchChatStream](https://riverml.xyz/0.18.0/api/stream/TwitchChatStream/) to handle the live streamed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if user is logged in (\"==\" active chat)\n",
    "import requests\n",
    "user = \"cohhcarnage\" # Change this to the user you want to check, e.g., epicdan22, zackrawrr, summit1g, mizkif, cohhcarnage, etc.\n",
    "response = requests.get(\"https://decapi.me/twitch/uptime/\"+user).text\n",
    "is_online = response != user+\" is offline\"\n",
    "print(is_online)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Connect to the Twitch chat using River\n",
    "from river import stream\n",
    "\n",
    "oauth = open('../../../No_sync/twitch_oauth','r').read()\n",
    "twitch_chat = stream.TwitchChatStream(\n",
    "    nickname=\"khliland\", # Exchange with your Twitch username\n",
    "    token=oauth,\n",
    "    channels=[user]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If the user is online, print the first messages\n",
    "interactive = False  # Set to True if you want to run this\n",
    "if is_online and interactive:\n",
    "    messages = 2\n",
    "    for item in twitch_chat:\n",
    "        print(item)\n",
    "        if messages > 1:\n",
    "            messages -= 1\n",
    "        else:\n",
    "            print(\"Puh, that's enough!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a river stream that counts the number of characters in the 'msg' part of the 'item' dictionary and plots it\n",
    "import matplotlib.pyplot as plt\n",
    "from river.stats import Mean\n",
    "from IPython import display\n",
    "import time\n",
    "messages = 20\n",
    "i = 0\n",
    "message_length = [np.nan] * messages\n",
    "mean_length = [np.nan] * messages\n",
    "mean = Mean()\n",
    "if is_online and interactive:\n",
    "    figure, ax = plt.subplots(figsize=(7,2))\n",
    "    plt.ion()\n",
    "    for item in twitch_chat:\n",
    "        if i < messages:\n",
    "            message_length[i] = len(item['msg'])\n",
    "            print(message_length[i])\n",
    "            mean.update(message_length[i]) # river stats\n",
    "            mean_length[i] = mean.get()\n",
    "            plt.clf()\n",
    "            plt.plot(list(range(messages)), message_length, label='Message length')\n",
    "            plt.plot(list(range(messages)), mean_length, label='Mean message length')\n",
    "            plt.xlim(0, messages-1)\n",
    "            plt.legend(loc='upper right')\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "            time.sleep(0.0001)\n",
    "            i += 1\n",
    "        else:\n",
    "            print(\"Puh, that's enough!\")\n",
    "            break\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Synthetic streams\n",
    "- _river_ can generate synthetic streams of various types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate Agrawal stream with classification type 0\n",
    "from river.datasets.synth import Agrawal\n",
    "dataset = Agrawal(classification_function=0, seed=42)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x, y in dataset.take(5):\n",
    "    print(list(x.values()), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Exercise\n",
    "- Here, you will be combining elements from various parts of the _river_ documentation.\n",
    "    - Dataset: Synthetic [Mv dataset](https://riverml.xyz/0.19.0/api/datasets/synth/Mv/), using 20,000 samples.\n",
    "        - Handle continuous (numbers) and categorical (string) variables in a pipeline (see [example](https://riverml.xyz/0.19.0/api/tree/iSOUPTreeRegressor/)).\n",
    "        - Continuous response with [$R^2$ metric](https://riverml.xyz/0.19.0/api/metrics/R2/).\n",
    "    - Model: [HoeffdingTreeRegressor*](https://riverml.xyz/0.19.0/api/tree/HoeffdingTreeRegressor/)\n",
    "        - Print performance [every 1000 samples](https://riverml.xyz/0.19.0/api/evaluate/iter-progressive-val-score/)\n",
    "  \n",
    " *HoeffdingTreeRegressor: This was originally called a Hoeffding Anytime Tree (HATT). It is an algorithm that is extremely efficient at updating decision trees with streaming data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Streaming forecasts\n",
    "- _river_ includes the SNARIMAX model, where N stands for _non-linear_, i.e., the (S)easonal (N)on-linear (A)uto(R)egressive (I)ntegrated (M)oving-(A)verage with e(X)ogenous inputs model.\n",
    "- The basic parameters match SARIMAX from the _statsmodels_ package, but are named _p/d/q/sp/sd/sq/m_.\n",
    "- If no regressor is specified, a pipeline containing a _StandardScaler_ and _LinearRegression_ is used.\n",
    "- No statistics or summary tables are produced, so summaries must be manually created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Airline passenger data\n",
    "- Monthly international passenger data from January 1949 through December 1960."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from river import datasets\n",
    "for t, (x, y) in enumerate(datasets.AirlinePassengers()):\n",
    "    print(x, y)\n",
    "    if t > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from river import time_series\n",
    "from river import metrics\n",
    "\n",
    "#period = 12\n",
    "model = time_series.SNARIMAX( p=3, d=1, q=3 )\n",
    "\n",
    "y_test = []\n",
    "for t, (x, y) in enumerate(datasets.AirlinePassengers()):\n",
    "    if t > 143-12: # Stop learning before the last 12 months\n",
    "        y_test.append(y)\n",
    "    else:\n",
    "        model.learn_one(y)\n",
    "        # model = model.learn_one(y)# For river < 0.21\n",
    "\n",
    "horizon = 12 # Predict 12 months into the future\n",
    "future = [\n",
    "    {'month': dt.date(year=1960, month=m, day=1)}\n",
    "    for m in range(1, horizon + 1)\n",
    "]\n",
    "forecast = model.forecast(horizon=horizon)\n",
    "metric = metrics.R2()\n",
    "for x, y_pred, y_truth in zip(future, forecast, y_test):\n",
    "    print(x['month'], f'{y_pred:.3f}', f'{y_truth:.3f}')\n",
    "    metric.update(y_truth, y_pred)\n",
    "    # metric = metric.update(y_truth, y_pred).get() # For river < 0.21\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### SARIMA + feature engineering\n",
    "- In addition to the original time series, we may add some freshly calculated exogenous variables.\n",
    "- In _river_'s SNARIMAX example, a distance function resembling a Radial Basis Function is applied to the months\n",
    "    - This results in 12 new features measuring the distance to other months in the year.\n",
    "    - In addition they include ordinal dates, i.e., day number since 0001-01-01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import calendar\n",
    "import math\n",
    "from river import compose\n",
    "from river import linear_model\n",
    "from river import optim\n",
    "from river import preprocessing\n",
    "\n",
    "def get_month_distances(x):\n",
    "    return {\n",
    "        calendar.month_name[month]: math.exp(-(x['month'].month - month) ** 2)\n",
    "        for month in range(1, 13)\n",
    "    }\n",
    "\n",
    "def get_ordinal_date(x):\n",
    "    return {'ordinal_date': x['month'].toordinal()}\n",
    "\n",
    "extract_features = compose.TransformerUnion(\n",
    "    get_ordinal_date,\n",
    "    get_month_distances\n",
    ")\n",
    "extract_features.transform_one({'month': dt.date(year=1960, month=1, day=1)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "extract_features.transform_one({'month': dt.date(year=1960, month=4, day=1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = (\n",
    "    extract_features |\n",
    "    time_series.SNARIMAX(\n",
    "        p=1,\n",
    "        d=0,\n",
    "        q=0,\n",
    "        m=12, # Seasonal model with period 12\n",
    "        sp=3,\n",
    "        sq=6,\n",
    "        regressor=(\n",
    "            preprocessing.StandardScaler() |\n",
    "            linear_model.LinearRegression(\n",
    "                intercept_init=110, # Help getting a better start\n",
    "                optimizer=optim.SGD(0.01),\n",
    "                intercept_lr=0.3\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modelling and predicting the AirlinePassengers dataset\n",
    "y_test = []\n",
    "for t, (x, y) in enumerate(datasets.AirlinePassengers()):\n",
    "    if t > 143-12: # Stop learning before the last 12 months\n",
    "        y_test.append(y)\n",
    "    else:\n",
    "        model.learn_one(x,y) # Note!: Dates are used as features\n",
    "        # model = model.learn_one(y)# For river < 0.21\n",
    "\n",
    "horizon = 12 # Predict 12 months into the future\n",
    "future = [\n",
    "    {'month': dt.date(year=1960, month=m, day=1)}\n",
    "    for m in range(1, horizon + 1)\n",
    "]\n",
    "forecast = model.forecast(horizon=horizon)\n",
    "metric = metrics.R2()\n",
    "for x, y_pred, y_truth in zip(future, forecast, y_test):\n",
    "    print(x['month'], f'{y_pred:.3f}', f'{y_truth:.3f}')\n",
    "    metric.update(y_truth, y_pred)\n",
    "    # metric = metric.update(y_truth, y_pred).get() # For river < 0.21\n",
    "\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "```{seealso} \n",
    ":class: tip\n",
    "\n",
    "## Resources\n",
    "- [scikit-learn's SGDClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)\n",
    "- [river's iter_array](https://riverml.xyz/dev/api/stream/iter-array/)\n",
    "- [river's LogisticRegression](https://riverml.xyz/dev/api/linear-model/LogisticRegression/)\n",
    "- [rivers's Mv dataset](https://riverml.xyz/0.19.0/api/datasets/synth/Mv/)\n",
    "- [river example of preprocessing in pipeline](https://riverml.xyz/0.19.0/api/tree/iSOUPTreeRegressor/)\n",
    "- [river's $R^2$ metric](https://riverml.xyz/0.19.0/api/metrics/R2/)\n",
    "- [river's HoeffdingTreeRegressor](https://riverml.xyz/0.19.0/api/tree/HoeffdingTreeRegressor/)\n",
    "- [river's iterative progressive validation score](https://riverml.xyz/0.19.0/api/evaluate/iter-progressive-val-score/)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IND320_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
