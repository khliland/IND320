{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# SARIMAX\n",
    "- The (extended) ARIMA family of methods is too big to be properly explained in this course.\n",
    "    - At NMBU, the course DAT320 goes deeper and explains the data generating processes.\n",
    "    - An online book with videos: [Forecasting: Principles and Practice](https://otexts.com/fpp3/).\n",
    "- We therefore skip (almost) directly to the regression models (inspired by [phosgene89's GitHub page](https://phosgene89.github.io/sarima.html), except for their errors) and their usage.\n",
    "- But first we introduce a dataset and the concepts of stationarity and autocorrelation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "__Stationarity:__\n",
    "- The distribution of the time series is independent of which part of the time series you look at.\n",
    "    - Trends, seasonality (cycles of fixed width) and changes in variance lead to non-stationarity.\n",
    "    - Differencing (first or second order discrete derivatives) can help.\n",
    "        - Seasonal differencing means the difference is not between neighbours but higher lags.\n",
    "- If the data is not stationary, pre-processing or modelling of the specific deviations from stationarity is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Wholesale price index (WPI) data\n",
    "- We will illustrate some concepts and models using the WPI data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Load Wholesale price index (WPI) data\n",
    "wpi1 = requests.get('https://www.stata-press.com/data/r12/wpi1.dta').content\n",
    "data = pd.read_stata(BytesIO(wpi1))\n",
    "data.index = data.t\n",
    "data['ln_wpi'] = np.log(data['wpi'])\n",
    "data['D.ln_wpi'] = data['ln_wpi'].diff()\n",
    "# Set the frequency to Quarterly Start, year ending October\n",
    "data.index.freq=\"QS-OCT\"\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Autocorrelation\n",
    "- [Autocorrelation](https://en.wikipedia.org/wiki/Autocorrelation) is the correlation between a stationary timeseries and a lagged version of itself.\n",
    "    - This is a measure of the time dependence in the series, i.e., lack of independence.\n",
    "    - Can be used to indicate the appropriate lag in moving average (MA) models.\n",
    "- [Partial autocorrelation](https://en.wikipedia.org/wiki/Partial_autocorrelation_function) is the autocorrelation when controlling for (regressed on) all intermediate time lags.\n",
    "    - Can be used to indicate the appropriate lag in autogregressive (AR) models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Autocorrelation and partial autocorrelation plots (raw data)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15,4))\n",
    "fig = sm.graphics.tsa.plot_acf(data.iloc[1:]['wpi'], lags=40, ax=axes[0])\n",
    "fig = sm.graphics.tsa.plot_pacf(data.iloc[1:]['wpi'], lags=40, ax=axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Graph data\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,3))\n",
    "\n",
    "# Levels\n",
    "axes[0].plot(data.index._mpl_repr(), data['wpi'], '-')\n",
    "axes[0].set(title='US Wholesale Price Index')\n",
    "\n",
    "# Log difference (attempting to improve stationarity)\n",
    "axes[1].plot(data.index._mpl_repr(), data['D.ln_wpi'], '-')\n",
    "axes[1].hlines(0, data.index[0], data.index[-1], 'r')\n",
    "axes[1].set(title='US Wholesale Price Index - difference of logs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Autocorrelation and partial autocorrelation plots \n",
    "# after applying the logarithm and differencing\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,3))\n",
    "fig = sm.graphics.tsa.plot_acf(data.iloc[1:]['D.ln_wpi'], lags=40, ax=axes[0])\n",
    "fig = sm.graphics.tsa.plot_pacf(data.iloc[1:]['D.ln_wpi'], lags=40, ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Autoregressive models in Python\n",
    "- Using the [_statsmodels_](https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html) package, the most complex model is the starting point.\n",
    "- Setting the various parameters of $SARIMAX(p, d, q)(P, D, Q, s)$, we can obtain any of the below mentioned models.\n",
    "    - SARIMAX(endog, exog=None, order=(1, 0, 0), seasonal_order=(0, 0, 0, 0), trend=None, ...)\n",
    "- For integer values of $p/d/q/P/D/Q$, all lags up to the integer are included. For more fine-grained control, lists can be applied, e.g., [1,0,1] includes lags 1 and 3, but not 2.\n",
    "- There are also various other parameters, e.g., a trend (none, constant, linear, quadratic, polynomial)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Lag operator\n",
    "- Back-shift $n$ time points, i.e., extracts the measurement $n$ time points before $t$.\n",
    "$$L^{n} y_{t} = y_{t-n}$$  \n",
    "- Combined with a vector of parameters $\\Psi$, we define a polynomial function\n",
    "$$\\Psi(L)^n y_t = y_t + \\psi_1 y_{t-1} + \\psi_2 y_{t-2} + ... + \\psi_n y_{t-n}$$\n",
    "- This will enable compact notation of the SARIMAX models, exchanging sums with the polynomial function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## AR - autoregressive models\n",
    "- For a (single variable) timeseries given by $\\{ y_{t} \\}$, we can specify the $AR(p)$ model as:\n",
    "  \n",
    "$$ y_{t} = \\theta_0 + \\sum\\limits_{i=1}^p \\theta_{i} y_{t-i} + \\epsilon_{t}$$\n",
    "  \n",
    "- i.e., the current time is a function of $p$ previous time points and a constant. \n",
    "- Here, $\\theta_0$ is a constant, $\\theta_{i}$ is the coefficient for the $p$-th time lag and $\\epsilon_{t}$ is the error. \n",
    "- This can be thought of as stacking subsets of a time series using a moving window and performing ordinary least squares on the resulting matrix/dataframe. \n",
    "    - In practice, the fitting is performed using maximum likelihood, so performing ordinary regression will not give exactly the same results.\n",
    "- Using the lag operator, $L^{n} y_{t} = y_{t-n}$, we can redefine the above equation in the form of a polynomial function, $\\Theta(L)^{p}$ (signs of coefficients will change) as:\n",
    "  \n",
    "$$ \\Theta(L)^{p} y_{t} = \\theta_0 + \\epsilon_{t}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit an AR(1) model (badly specified due to non-stationarity)\n",
    "mod = sm.tsa.statespace.SARIMAX(data['wpi'], trend='c', order=(1,0,0)) # trend='c' adds a constant\n",
    "res = mod.fit(disp=False)\n",
    "print(res.summary()) # AIC gives us a measure of fit for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## MA - moving average models\n",
    "- MA models are functions of previous errors, rather than previous measurements. \n",
    "- We can define an $MA(q)$ model as:\n",
    "  \n",
    "$$ y_{t} = \\phi_0 + \\sum\\limits_{i=1}^q \\phi_{i} \\epsilon_{t-i} + \\epsilon_{t}$$\n",
    "$$ = \\phi_0 + \\Phi(L)^{q} \\epsilon_{t}.$$\n",
    "  \n",
    "- Here, $q$ is the number of time lags and $\\Phi(L)^{q}$ is defined as $\\Theta$ above, but using the error terms and $\\epsilon_{t}$ is with respect to the current model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit an MA(1) model (disregarding the obvious autocorrelation)\n",
    "mod = sm.tsa.statespace.SARIMAX(data['wpi'], trend='c', order=(0,0,1))\n",
    "res = mod.fit(disp=False)\n",
    "print(res.summary()) # AIC gives us a measure of fit for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## ARMA - autoregressive moving average models\n",
    "- When we take the sum of $AR(p)$ and $MA(q)$ models of the same time series, we get $ARMA(p,q)$ models:\n",
    "  \n",
    "$$ y_{t} = \\theta_0 + \\sum\\limits_{i=1}^p \\theta_{i} y_{t-i} + \\sum\\limits_{i=1}^q \\phi_{i} \\epsilon_{t-i} + \\epsilon_{t}$$\n",
    "\n",
    "- which can be reformulated to:\n",
    "\n",
    "$$ \\Theta(L)^{p} y_{t} = \\theta_0 + \\Phi(L)^{q} \\epsilon_{t}$$\n",
    "  \n",
    "- Again, $\\epsilon_{t}$ is with respect to the current model, but shares name with the previous models.\n",
    "- This model is learning both from seeing previous samples and from how well these were predicted at previous time steps, thus it can tackle changes in the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit an ARMA(1,1) model (badly specified due to non-stationarity)\n",
    "mod = sm.tsa.statespace.SARIMAX(data['wpi'], trend='c', order=(1,0,1))\n",
    "res = mod.fit(disp=False)\n",
    "print(res.summary()) # AIC gives us a measure of fit for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## ARIMA - autoregressive integrated moving average models\n",
    "- To help compensate for lack of stationarity, we add an integration operator, $\\Delta^{d}$, defined as:\n",
    "  \n",
    "$$y_{t}^{[d]} = \\Delta^{d} y_{t} = y_{t}^{[d-1]} - y_{t-1}^{[d-1]}.$$\n",
    "  \n",
    "- Here, $y_{t}^{[0]} = y_{t}$ and the degree of differensing is $d$.\n",
    "- For instance with $d=2$:\n",
    "\n",
    "$$y_{t}^{[2]} = \\Delta^{2} y_{t} = y_{t}^{[1]} - y_{t-1}^{[1]} $$\n",
    "$$= y_{t}^{[0]} - y_{t-1}^{[0]} - y_{t-1}^{[0]} + y_{t-2}^{[0]} = y_{t} - 2 y_{t-1} + y_{t-2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "- An $ARMA(p, q)$ model where $y_{t}$ is exchanged with $y_{t}^{[d]}$ would look like this:\n",
    "  \n",
    "$$ \\Theta(L)^{p} y_{t}^{[d]} = \\Phi(L)^{q} \\epsilon_{t}$$\n",
    "\n",
    "- The constant is often omitted and assumed absorbed by the integration. Only the time series is integrated, not the errors.  \n",
    "- Reformulating this using the integration operator, we get an $ARIMA(p,d,q)$ model:\n",
    "  \n",
    "$$ \\Theta(L)^{p} \\Delta^{d} y_{t} = \\Phi(L)^{q} \\epsilon_{t}$$\n",
    "  \n",
    "- This model has the properties of the ARMA model, but in addition does the differensing for us for stationarity.\n",
    "- The terms can be reorganised to get predictions on the original scale instead of predicting difference values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit an ARIMA(1,1,1) model\n",
    "mod = sm.tsa.statespace.SARIMAX(data['wpi'], trend=None, order=(1,1,1))\n",
    "res = mod.fit(disp=False)\n",
    "print(res.summary()) # AIC gives us a measure of fit for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Since the data are quarterly, we can add a seasonal component by including a fourth time lag to moving average\n",
    "# Fit an ARIMA(1,1,[1,0,0,1]) model\n",
    "mod = sm.tsa.statespace.SARIMAX(data['wpi'], trend=None, order=(1,1,[1,0,0,1]))\n",
    "res = mod.fit(disp=False)\n",
    "print(res.summary()) # AIC gives us a measure of fit for comparison\n",
    "# What about a linear trend? (trend='t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## SARIMA - seasonal autoregressive integrated moving average models\n",
    "- SARIMA shares some resemblance with the STL decomposition introduced previously.\n",
    "- For seasons of length $s$, the seasonal part is obtained by applying an ARIMA model with lags, $P$ and $Q$, and integration time, $D$, that are multiples of $s$, i.e., if $P=2$, the included time points would be $t-1s$ and $t-2s$.\n",
    "  \n",
    "$$ \\theta(L^{s})^{P} \\Delta_{s}^{D} y_{t} = \\phi(L^{s})^{Q} \\epsilon_{t} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- After the seasonal part has been removed, another $ARIMA(p, d, q)$ applied to $\\Delta_{s}^{D} y_{t}$ which is equivalent to multiplying the two models together.\n",
    "- The $SARIMA(p, d, q)(P, D, Q, s)$ model then becomes:\n",
    "  \n",
    "$$ \\Theta(L)^{p} \\theta(L^{s})^{P} \\Delta^{d} \\Delta_{s}^{D} y_{t} = \\Phi(L)^{q} \\phi(L^{s})^{Q} \\epsilon_{t}$$\n",
    "  \n",
    "- This model has the ability to combine experience from previous timepoints with seasonal trends. \n",
    "    - Or if one sets the ARIMA parameters $p=0$, $d=0$, $q=0$, one can have a pure seasonal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using SARIMA for seasonality instead of the fourth time lag to moving average.\n",
    "# Fit a SARIMA(1,1,1)(1,1,1,4) model\n",
    "mod = sm.tsa.statespace.SARIMAX(data['wpi'], trend=None, order=(1,1,1), seasonal_order=(1,1,1,4))\n",
    "res = mod.fit(disp=False)\n",
    "print(res.summary()) # AIC gives us a measure of fit for comparison (no improvement here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Exogenous variables\n",
    "- As we showed in the previous chapter, it is possible to make a model purely on other variables measured at the same time, $t$.\n",
    "- Including these variables into ARIMA and SARIMA, we get the ARIMAX and SARIMAX models.\n",
    "- In practice, we paste on an extra coefficient vector, $\\beta$, and variables, $X_{t}$, to the models, here noted as sums of products $\\beta_{i} x^{i}_{t}$: \n",
    "- $ARIMAX(p, d, q)$:\n",
    "  \n",
    "$$\\Theta(L)^{p} \\Delta^{d} y_{t} = \\Phi(L)^{q} \\epsilon_{t} + \\sum_{i=1}^{n} \\beta_{i} x^{i}_{t}$$\n",
    "  \n",
    "- $SARIMAX(p, d, q)(P, D, Q, s)$:\n",
    "  \n",
    "$$\\Theta(L)^{p} \\theta(L^{s})^{P} \\Delta^{d} \\Delta_{s}^{D} y_{t} = \\Phi(L)^{q} \\phi(L^{s})^{Q} \\epsilon_{t} + \\sum_{i=1}^{n} \\beta_{i} x^{i}_{t}$$\n",
    "  \n",
    "- The final model, thus includes autogression and moving averages, can perform differences, deals with seasonality and can leverage external variables from the same timepoint as the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the FinalData sheet of the OilExchange.xlsx file using Pandas again\n",
    "import pandas as pd\n",
    "OilExchange = pd.read_excel('../../data/OilExchange.xlsx', sheet_name='FinalData')\n",
    "OilExchange.index = OilExchange.Date\n",
    "OilExchange.index.freq = \"MS\" # Set the frequency to Month Start\n",
    "OilExchange.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit a SARIMAX(1,1,1)(1,1,1,12) model with exogenous variables (closing our eyes, as we know little about the data)\n",
    "mod = sm.tsa.statespace.SARIMAX(OilExchange['PerEURO'], exog=OilExchange.loc[:, OilExchange.columns[3:-6]], \\\n",
    "                                trend='c', order=(1,1,1), seasonal_order=(1,1,1,12))\n",
    "res = mod.fit(disp=False)\n",
    "print(res.summary()) # AIC gives us a measure of fit for comparison (no improvement here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Exercise\n",
    "- Play with the OilExchange data.\n",
    "- See if you can improve the fit of the model by adjusting lags and removing the least significant terms in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## SARIMAX prediction\n",
    "- One-step-ahead prediction uses the estimated parameters and samples within the lags of the model to predict the next time point.\n",
    "    - This means that the predictions will stay relatively close to the true values, never predicting more than one step away from the truth.\n",
    "- Dynamic prediction predicts one step as above, then uses predicted values as input instead of true values.\n",
    "    - This means the predictions can deviate from the truth over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Refit the model on the training set (up to 2013-01-01) to estimate the parameters\n",
    "mod = sm.tsa.statespace.SARIMAX(OilExchange['PerEURO'].loc[:'2013-01-01'], \\\n",
    "                                OilExchange.loc[:, OilExchange.columns[3:-4]].loc[:'2013-01-01'], \\\n",
    "    trend='c', order=(1,1,1), seasonal_order=(1,1,1,12))\n",
    "res = mod.fit(disp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get predictions for the whole dataset\n",
    "mod = sm.tsa.statespace.SARIMAX(OilExchange['PerEURO'], OilExchange.loc[:, OilExchange.columns[3:-4]], \\\n",
    "    trend='c', order=(1,1,1), seasonal_order=(1,1,1,12))\n",
    "\n",
    "res = mod.filter(res.params) # One-step-ahead predictions using parameters from previous fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In-sample one-step-ahead prediction wrapper function\n",
    "predict = res.get_prediction()\n",
    "predict_ci = predict.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dynamic predictions starting from 2013-01-01\n",
    "predict_dy = res.get_prediction(dynamic='2013-01-01')\n",
    "predict_dy_ci = predict_dy.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compare the one-step-ahead predictions to the dynamic predictions\n",
    "fig, ax = plt.subplots(figsize=(9,4))\n",
    "npre = 4\n",
    "ax.set(title='Exchange rate', xlabel='Date', ylabel='Per EURO')\n",
    "\n",
    "# Plot data points\n",
    "OilExchange.loc['2012-01-01':, 'PerEURO'].plot(ax=ax, style='o', label='Observed')\n",
    "\n",
    "# Plot predictions\n",
    "predict.predicted_mean.loc['2012-01-01':].plot(ax=ax, style='r--', label='One-step-ahead forecast')\n",
    "ci = predict_ci.loc['2012-01-01':]\n",
    "ax.fill_between(ci.index, ci.iloc[:,0], ci.iloc[:,1], color='r', alpha=0.1)\n",
    "predict_dy.predicted_mean.loc['2012-01-01':].plot(ax=ax, style='g', label='Dynamic forecast (2013)')\n",
    "ci = predict_dy_ci.loc['2012-01-01':]\n",
    "ax.fill_between(ci.index, ci.iloc[:,0], ci.iloc[:,1], color='g', alpha=0.1)\n",
    "\n",
    "legend = ax.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Questercise\n",
    "- Does the model made in the previous exercise improve the predictions as visualized above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "```{seealso} \n",
    ":class: tip\n",
    "\n",
    "## Resources\n",
    "- [Book and video lectures on Forecasting: Principles and Practice](https://otexts.com/fpp3/)\n",
    "- [Wikipedia: Autocorrelation](https://en.wikipedia.org/wiki/Autocorrelation)\n",
    "- [Wikipedia: Partial autocorrelation](https://en.wikipedia.org/wiki/Partial_autocorrelation_function)\n",
    "- [statsmodels' SARIMAX documentation](https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html)\n",
    "- [statsmodels' SARIMAX example](https://www.statsmodels.org/stable/examples/notebooks/generated/statespace_sarimax_stata.html)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IND320_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
